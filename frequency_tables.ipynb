{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# converts binary to decimal\n",
    "def binaryToDecimal(binary):\n",
    " \n",
    "    decimal, i = 0, 0\n",
    "    while(binary != 0):\n",
    "        dec = binary % 10\n",
    "        decimal = decimal + dec * pow(2, i)\n",
    "        binary = binary//10\n",
    "        i += 1\n",
    "    print(decimal)\n",
    "\n",
    "binaryToDecimal(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "# top values = 4 because we pics top two qubits in the binary classification\n",
    "topValues = 4\n",
    "\n",
    "def findPrepareFrequencyTable(filename, frequency_filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    # df.fillna(0)\n",
    "    df.fillna(0, inplace=True) # replace empty cells with zero\n",
    "    df.to_csv(filename, index=False)\n",
    "    # df = pd.read_csv('nairobi_processed_states.csv')\n",
    "\n",
    "    frequency_table = np.zeros(128)\n",
    "\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "    #skips header\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            row = np.array(row)\n",
    "            row = row[1:] # skips 1st element in row which contains total counts of all states\n",
    "            # print(row.astype(float))\n",
    "            # print(row[34])\n",
    "            max_indexes = np.argsort(row)[::-1][:topValues]\n",
    "            # print(max_indexes)\n",
    "            for index in max_indexes:\n",
    "                if index==128:\n",
    "                    print(\"Index :\", index)\n",
    "                    # pdb.set_trace()\n",
    "\n",
    "                # print(index)\n",
    "                frequency_table[index] += 1\n",
    "            \n",
    "            # break\n",
    "    frequency_table\n",
    "    # np.save(frequency_filename, frequency_table)\n",
    "    # pdb.set_trace()\n",
    "    pd.DataFrame(frequency_table).to_csv(frequency_filename, index = False)\n",
    "\n",
    "class3_nairobi_filename = 'class3_nairobi_processed_states.csv'\n",
    "class3_nairobi_frequency_filename = \"class3_nairobi_frequency_table.csv\"\n",
    "class6_nairobi_filename = 'class6_nairobi_processed_states.csv'\n",
    "class6_nairobi_frequency_filename = \"class6_nairobi_frequency_table.csv\"\n",
    "class9_nairobi_filename = 'class9_nairobi_processed_states.csv'\n",
    "class9_nairobi_frequency_filename = \"class9_nairobi_frequency_table.csv\"\n",
    "\n",
    "class3_lagos_filename = 'class3_lagos_processed_states.csv'\n",
    "class3_lagos_frequency_filename = \"class3_lagos_frequency_table.csv\"\n",
    "class6_lagos_filename = 'class6_lagos_processed_states.csv'\n",
    "class6_lagos_frequency_filename = \"class6_lagos_frequency_table.csv\"\n",
    "class9_lagos_filename = 'class9_lagos_processed_states.csv'\n",
    "class9_lagos_frequency_filename = \"class9_lagos_frequency_table.csv\"\n",
    "\n",
    "class3_perth_filename = 'class3_perth_processed_states.csv'\n",
    "class3_perth_frequency_filename = \"class3_perth_frequency_table.csv\"\n",
    "class6_perth_filename = 'class6_perth_processed_states.csv'\n",
    "class6_perth_frequency_filename = \"class6_perth_frequency_table.csv\"\n",
    "class9_perth_filename = 'class9_perth_processed_states.csv'\n",
    "class9_perth_frequency_filename = \"class9_perth_frequency_table.csv\"\n",
    "\n",
    "\n",
    "class3_truth_filename = 'class3_truth_processed_states.csv'\n",
    "class3_truth_frequency_filename = \"class3_truth_frequency_table.csv\"\n",
    "class6_truth_filename = 'class6_truth_processed_states.csv'\n",
    "class6_truth_frequency_filename = \"class6_truth_frequency_table.csv\"\n",
    "class9_truth_filename = 'class9_truth_processed_states.csv'\n",
    "class9_truth_frequency_filename = \"class9_truth_frequency_table.csv\"\n",
    "\n",
    "# oslo_filename = 'oslo_processed_states.csv'\n",
    "# oslo_frequency_filename = \"oslo_frequency_table.csv\"\n",
    "# perth_filename = 'perth_processed_states.csv'\n",
    "# perth_frequency_filename = \"perth_frequency_table.csv\"\n",
    "# ground_truth_filename = 'ground_truth_processed_states.csv'\n",
    "# ground_truth_frequency_filename = \"ground_truth_frequency_table.csv\"\n",
    "\n",
    "# class3_lagos_processed_states.csv\n",
    "# filename_list = [nairobi_filename, perth_filename, oslo_filename, ground_truth_filename]\n",
    "# frequency_filename_list = [nairobi_frequency_filename, perth_frequency_filename, oslo_frequency_filename, ground_truth_frequency_filename]\n",
    "filename_list = [class3_nairobi_filename, \n",
    "                 class6_nairobi_filename,\n",
    "                 class9_nairobi_filename,\n",
    "                 class3_lagos_filename,\n",
    "                 class6_lagos_filename,\n",
    "                 class9_lagos_filename,\n",
    "                 class3_perth_filename,\n",
    "                 class6_perth_filename,\n",
    "                 class9_perth_filename,\n",
    "                 class3_truth_filename,\n",
    "                 class6_truth_filename,\n",
    "                 class9_truth_filename]\n",
    "\n",
    "\n",
    "frequency_filename_list = [class3_nairobi_frequency_filename,\n",
    "                           class6_nairobi_frequency_filename,\n",
    "                           class9_nairobi_frequency_filename,\n",
    "                           class3_lagos_frequency_filename,\n",
    "                           class6_lagos_frequency_filename,\n",
    "                           class9_lagos_frequency_filename,\n",
    "                           class3_perth_frequency_filename,\n",
    "                           class6_perth_frequency_filename,\n",
    "                           class9_perth_frequency_filename,\n",
    "                           class3_truth_frequency_filename,\n",
    "                           class6_truth_frequency_filename,\n",
    "                           class9_truth_frequency_filename,]\n",
    "\n",
    "# preparing frequency table\n",
    "for filename, frequency_filename in zip(filename_list, frequency_filename_list):\n",
    "\n",
    "    findPrepareFrequencyTable(filename, frequency_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2181. 1893. 1479.  997.  476. 5156. 2743. 1293. 2903. 1237. 1524.  521.\n",
      " 2987. 1234. 1156. 1614. 1173.    0.  318.   34.    0.    0.  323.   34.\n",
      "    0.   68.   34.    0. 6459.    0.    0.  119.  129.    0.    0.   51.\n",
      "    0. 4525.    0.    0.   17.    0.    0.   17.    0.    0.    0.   17.\n",
      "    0.   12.    0.    0.    0. 2790.  165. 1705. 3246. 2323.   90. 1718.\n",
      " 1155.   46. 1147. 1921. 3853.  391.  238.    0.  661.  702. 1463.   51.\n",
      "  187.  323.    0.  606.  748.  533.   17. 3099. 2874.  358. 5662. 1624.\n",
      " 4066. 2250.   29.    0.    0.   34.   51.   34.  334.   34.    0.    0.\n",
      "    0.    0.    0.   51.    0.    0.    0.    0.    0.   34.  385.    0.\n",
      "  301.   51.  827. 1098. 2651. 1836.    0.   17.    0.  561.    0.    0.\n",
      "    0.   68.    0.    0.   17.  153.  210.    0.]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# nairobiFrequencyArray = np.loadtxt('nairobi_frequency_table.csv', delimiter=',')[1:]\n",
    "# print(nairobiFrequencyArray)\n",
    "truthFrequencyArray = np.loadtxt('ground_truth_frequency_table.csv', delimiter=',')[1:]\n",
    "print(truthFrequencyArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2181. 1893. 1479.  997.  476. 5156. 2743. 1293. 2903. 1237. 1524.  521.\n",
      " 2987. 1234. 1156. 1614. 1173.    0.  318.   34.    0.    0.  323.   34.\n",
      "    0.   68.   34.    0. 6459.    0.    0.  119.  129.    0.    0.   51.\n",
      "    0. 4525.    0.    0.   17.    0.    0.   17.    0.    0.    0.   17.\n",
      "    0.   12.    0.    0.    0. 2790.  165. 1705. 3246. 2323.   90. 1718.\n",
      " 1155.   46. 1147. 1921. 3853.  391.  238.    0.  661.  702. 1463.   51.\n",
      "  187.  323.    0.  606.  748.  533.   17. 3099. 2874.  358. 5662. 1624.\n",
      " 4066. 2250.   29.    0.    0.   34.   51.   34.  334.   34.    0.    0.\n",
      "    0.    0.    0.   51.    0.    0.    0.    0.    0.   34.  385.    0.\n",
      "  301.   51.  827. 1098. 2651. 1836.    0.   17.    0.  561.    0.    0.\n",
      "    0.   68.    0.    0.   17.  153.  210.    0.]\n",
      "6459.0\n"
     ]
    }
   ],
   "source": [
    "# also check if the top n dominant state or states in this numpy array are also included in the cluster with high cluster frequency.\n",
    "\n",
    "# array = np.loadtxt('nairobi_member_indices_list.csv')\n",
    "# nairobiFrequencyArray = np.nonzero(nairobiFrequencyArray)\n",
    "print(truthFrequencyArray)\n",
    "\n",
    "print(np.max(truthFrequencyArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 : 1173.0\n",
      "23 : 34.0\n",
      "24 : 0.0\n",
      "27 : 0.0\n",
      "28 : 6459.0\n",
      "37 : 4525.0\n",
      "47 : 17.0\n",
      "51 : 0.0\n",
      "52 : 0.0\n",
      "59 : 1718.0\n",
      "66 : 238.0\n",
      "70 : 1463.0\n",
      "74 : 0.0\n",
      "76 : 748.0\n",
      "82 : 5662.0\n",
      "88 : 0.0\n",
      "91 : 34.0\n",
      "95 : 0.0\n",
      "100 : 0.0\n",
      "121 : 68.0\n"
     ]
    }
   ],
   "source": [
    "perth = np.array([ 16,  23,  24,  27,  28,  37,  47,  51,  52,  59,  66,  70,  74,\n",
    "        76,  82,  88,  91,  95, 100, 121])\n",
    "for index in perth:\n",
    "    print(int(index),\":\",truthFrequencyArray[int(index)])\n",
    "    # print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nairobiFrequencyArray[95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40,  0, 57, 63, 90, 94, 20,  2,  6, 96, 10, 47, 59, 95,  8, 18, 17,\n",
       "       14, 23, 22, 16, 92, 71, 62, 25, 34,  4, 27, 64, 67, 12, 37, 65,  7,\n",
       "       44, 31, 80, 29, 24, 58, 39, 15, 19, 51, 79,  1, 35, 70, 76, 42, 61,\n",
       "       87, 66, 56, 33, 91, 73, 60, 72, 69, 84, 81, 83, 43, 75, 86, 11, 49,\n",
       "       38, 74, 54, 97,  9, 26, 41, 13, 50, 52, 30, 93,  3, 45, 68, 36, 77,\n",
       "       21,  5, 48, 85, 89, 88, 28, 82, 78, 55, 32, 53, 46, 98])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives only non zero indexes of the top four states collected from all the circuits\n",
    "# nonZeroIndexes = np.argsort(nairobiFrequencyArray[np.nonzero(nairobiFrequencyArray>0)])[::-1]\n",
    "nonZeroIndexes = np.argsort(nairobiFrequencyArray[np.nonzero(nairobiFrequencyArray)])[::-1]\n",
    "\n",
    "nonZeroIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nairobiFrequencyArray[nonZeroIndexes]\n",
    "\n",
    "np.size(nonZeroIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testIndices = nonZeroIndexes[:10]\n",
    "testIndices = np.array([40,  0, 1347, 63, 90, 94, 20,  2,  6, 96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isin(testIndices, nonZeroIndexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.nonzero(nairobiFrequencyArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7260.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nairobiFrequencyArray[nonZeroIndexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0, '1': 2, '2': 4, '3': 6, '4': 8}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDict = dict()\n",
    "\n",
    "for i in range(5):\n",
    "    testDict[str(i)] = i*2\n",
    "\n",
    "testDict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantumML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae01cfc27ce541cec8ebec6509001cf1232fcca4222e4584ac46326fcb6f99d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
